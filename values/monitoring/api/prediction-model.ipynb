{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  \n",
    "import joblib          \n",
    "\n",
    "# provide file paths to logs and metrics files\n",
    "log_paths = [\n",
    "    'log_file_1',\n",
    "    'log_file2',\n",
    "    # … \n",
    "]\n",
    "metric_paths = [\n",
    "    'metrics_file_1',\n",
    "    'metrics_file2',\n",
    "    # … \n",
    "]\n",
    "\n",
    "def process_single_run(log_path, metrics_path):\n",
    "    makespan = {}\n",
    "    task_counts = {}\n",
    "    intervals = {}\n",
    "\n",
    "    with open(log_path, 'r') as f:\n",
    "        try:\n",
    "            log_data = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise RuntimeError(f\"Błąd przy parsowaniu pliku logów: {log_path}\\n{e}\")\n",
    "\n",
    "    for src in log_data:\n",
    "        wf   = src.get('log.attributes.workflowId')\n",
    "        jb   = src.get('log.attributes.jobId')\n",
    "        body = src.get('body')\n",
    "        t    = pd.to_datetime(src.get('time'))\n",
    "        if wf is None:\n",
    "            continue\n",
    "\n",
    "        # Makespan\n",
    "        if body == 'Job started':\n",
    "            st, fi = makespan.get(wf, [None, None])\n",
    "            if st is None or t < st:\n",
    "                st = t\n",
    "            makespan[wf] = [st, fi]\n",
    "        elif body == 'Job finished':\n",
    "            st, fi = makespan.get(wf, [None, None])\n",
    "            if fi is None or t > fi:\n",
    "                fi = t\n",
    "            makespan[wf] = [st, fi]\n",
    "\n",
    "        # Task counts\n",
    "        if body == 'Job started':\n",
    "            task = src.get('log.attributes.name')\n",
    "            if task:\n",
    "                task_counts[(wf, task)] = task_counts.get((wf, task), 0) + 1\n",
    "\n",
    "        # Concurrency\n",
    "        if body in ('Job started', 'Job finished') and jb is not None:\n",
    "            key = (wf, jb)\n",
    "            st, en = intervals.get(key, [None, None])\n",
    "            if body == 'Job started':\n",
    "                st = t\n",
    "            else:\n",
    "                en = t\n",
    "            intervals[key] = [st, en]\n",
    "\n",
    "    # Makespan\n",
    "    makespan_final = {}\n",
    "    for wf, (st, fi) in makespan.items():\n",
    "        if st is None or fi is None:\n",
    "            continue\n",
    "        makespan_final[wf] = (fi - st).total_seconds()\n",
    "\n",
    "    # Task counts\n",
    "    rows = []\n",
    "    for (wf, task), cnt in task_counts.items():\n",
    "        rows.append({'workflowId': wf, 'task_name': task, 'count': cnt})\n",
    "    if rows:\n",
    "        df_tasks = pd.DataFrame(rows)\n",
    "        task_counts_ct = df_tasks.pivot_table(\n",
    "            index='workflowId', columns='task_name', values='count', fill_value=0\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        task_counts_ct = pd.DataFrame({'workflowId': list(makespan_final.keys())})\n",
    "\n",
    "    # Max concurrency per workflow\n",
    "    def max_concurrency(interval_list):\n",
    "        events = []\n",
    "        for (st, en) in interval_list:\n",
    "            events.append((st, 1))\n",
    "            events.append((en, -1))\n",
    "        events.sort()\n",
    "        cur = mx = 0\n",
    "        for _, delta in events:\n",
    "            cur += delta\n",
    "            mx = max(mx, cur)\n",
    "        return mx\n",
    "\n",
    "    concurrency_rows = []\n",
    "    by_wf = defaultdict(list)\n",
    "    for (wf, jb), (st, en) in intervals.items():\n",
    "        if st is None or en is None:\n",
    "            continue\n",
    "        by_wf[wf].append((st, en))\n",
    "\n",
    "    for wf, lst in by_wf.items():\n",
    "        concurrency_rows.append({'workflowId': wf, 'max_concurrency': max_concurrency(lst)})\n",
    "    if concurrency_rows:\n",
    "        df_concurrency = pd.DataFrame(concurrency_rows)\n",
    "    else:\n",
    "        df_concurrency = pd.DataFrame({'workflowId': list(makespan_final.keys()), 'max_concurrency': 0})\n",
    "\n",
    "    # CPU-info (na razie same zera, bo nie zbieramy)\n",
    "    cpu_agg = pd.DataFrame({\n",
    "        'workflowId': list(makespan_final.keys()),\n",
    "        'cpu_speed': 0, 'cpu_cores': 0, 'cpu_pcores': 0\n",
    "    })\n",
    "\n",
    "    cpu_mem_stats = defaultdict(lambda: [0, 0.0, float('inf'), float('-inf'), 0.0])\n",
    "\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        try:\n",
    "            metrics_data = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise RuntimeError(f\"Błąd przy parsowaniu pliku metryk: {metrics_path}\\n{e}\")\n",
    "\n",
    "    for src in metrics_data:\n",
    "        if isinstance(src, dict) and '_source' in src:\n",
    "            src = src['_source']\n",
    "\n",
    "        wf   = src.get('metric.attributes.workflowId')\n",
    "        name = src.get('name')\n",
    "        val  = src.get('value')\n",
    "        if wf is None or val is None or name not in ('cpu-usage', 'memory-usage'):\n",
    "            continue\n",
    "        key = (wf, name)\n",
    "        cnt, s, mn, mx, sq = cpu_mem_stats[key]\n",
    "        cnt += 1\n",
    "        s   += val\n",
    "        mn   = min(mn, val)\n",
    "        mx   = max(mx, val)\n",
    "        sq  += val * val\n",
    "        cpu_mem_stats[key] = [cnt, s, mn, mx, sq]\n",
    "\n",
    "    rows = []\n",
    "    for (wf, m_), (cnt, s, mn, mx, sq) in cpu_mem_stats.items():\n",
    "        mean = s / cnt\n",
    "        var  = (sq / cnt) - mean * mean\n",
    "        std  = np.sqrt(var) if var > 0 else 0.0\n",
    "        rows.append({\n",
    "            'workflowId': wf,\n",
    "            f'{m_}_mean': mean,\n",
    "            f'{m_}_max':  mx,\n",
    "            f'{m_}_min':  mn,\n",
    "            f'{m_}_std':  std\n",
    "        })\n",
    "    if rows:\n",
    "        df_cpu_mem = pd.DataFrame(rows)\n",
    "        df_cpu_mem = df_cpu_mem.groupby('workflowId').first().reset_index()\n",
    "    else:\n",
    "        df_cpu_mem = pd.DataFrame({\n",
    "            'workflowId': list(makespan_final.keys()),\n",
    "            'cpu-usage_mean': 0, 'cpu-usage_max': 0, 'cpu-usage_min': 0, 'cpu-usage_std': 0,\n",
    "            'memory-usage_mean': 0, 'memory-usage_max': 0, 'memory-usage_min': 0, 'memory-usage_std': 0\n",
    "        })\n",
    "\n",
    "    df_makespan = pd.DataFrame([{'workflowId': wf, 'makespan': ms} for wf, ms in makespan_final.items()])\n",
    "    df_run = (\n",
    "        df_makespan\n",
    "        .merge(task_counts_ct, on='workflowId', how='left')\n",
    "        .merge(df_concurrency, on='workflowId', how='left')\n",
    "        .merge(cpu_agg, on='workflowId', how='left')\n",
    "        .merge(df_cpu_mem, on='workflowId', how='left')\n",
    "        .fillna(0)\n",
    "    )\n",
    "    return df_run\n",
    "\n",
    "\n",
    "n_runs = len(log_paths)\n",
    "all_runs = []\n",
    "\n",
    "for log_path, metrics_path in tqdm(zip(log_paths, metric_paths), total=n_runs, desc=\"Przetwarzam pliki\"):\n",
    "    df_run = process_single_run(log_path, metrics_path)\n",
    "    all_runs.append(df_run)\n",
    "\n",
    "df_all = pd.concat(all_runs, ignore_index=True)\n",
    "\n",
    "y = df_all['makespan']\n",
    "X = df_all.drop(columns=['workflowId', 'makespan'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    alphas = np.logspace(-3, 3, 50)\n",
    "    model_cv = RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "    model_cv.fit(X_train, y_train)\n",
    "\n",
    "    pred = model_cv.predict(X_test)\n",
    "    y_true.append(y_test.values[0])\n",
    "    y_pred.append(pred[0])\n",
    "\n",
    "mae  = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2   = r2_score(y_true, y_pred)\n",
    "print(f\"--- Ocena LOO-CV (RidgeCV) ---\")\n",
    "print(f\"LOO  MAE: {mae:.2f}\")\n",
    "print(f\"LOO RMSE: {rmse:.2f}\")\n",
    "print(f\"LOO   R²: {r2:.2f}\")\n",
    "\n",
    "\n",
    "# Model Ridg\n",
    "alphas_final = np.logspace(-3, 3, 50)\n",
    "ridge_final = RidgeCV(alphas=alphas_final, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_final.fit(X, y)\n",
    "\n",
    "# Model LightGBM \n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': ['mae', 'rmse'],\n",
    "    'num_leaves': 4,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'lambda_l2': 1.0,\n",
    "    'verbosity': -1\n",
    "}\n",
    "lgbm_final = lgb.train(params, train_data)\n",
    "lgb.plot_importance(lgbm_final, max_num_features=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save models\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(ridge_final, 'ridge_model.pkl')\n",
    "lgbm_final.save_model('lgbm_model.txt')\n",
    "\n",
    "\n",
    "def predict_makespan_from_paths(new_log_path: str, new_metrics_path: str, \n",
    "                                model_type: str = 'lgbm') -> float:\n",
    "    \"\"\"\n",
    "    Wczytuje nowy plik logów + metryk, buduje cechy w taki sam sposób jak przy treningu,\n",
    "    skaluje je przy użyciu zapisanego scaler.pkl i zwraca predykowany makespan.\n",
    "    \n",
    "    Args:\n",
    "        new_log_path (str): ścieżka do pliku JSON z logami pojedynczego uruchomienia.\n",
    "        new_metrics_path (str): ścieżka do pliku JSON z metrykami dla tego uruchomienia.\n",
    "        model_type (str): 'ridge' lub 'lgbm' (domyślnie 'lgbm').\n",
    "    \n",
    "    Returns:\n",
    "        float: predykcja makespanu (w sekundach).\n",
    "    \"\"\"\n",
    "    df_run = process_single_run(new_log_path, new_metrics_path)\n",
    "    if df_run.shape[0] != 1:\n",
    "        raise ValueError(\"Funkcja process_single_run zwróciła != 1 wiersza. Sprawdź pliki wejściowe.\")\n",
    "    \n",
    "    X_new = df_run.drop(columns=['workflowId', 'makespan'], errors='ignore')\n",
    "    original_cols = list(X.columns)\n",
    "    for col in original_cols:\n",
    "        if col not in X_new.columns:\n",
    "            X_new[col] = 0\n",
    "    X_new = X_new[original_cols]\n",
    "    \n",
    "    scaler_loaded = joblib.load('scaler.pkl')\n",
    "    X_new[num_cols] = scaler_loaded.transform(X_new[num_cols])\n",
    "    \n",
    "    if model_type == 'ridge':\n",
    "        model_loaded = joblib.load('ridge_model.pkl')\n",
    "        pred = model_loaded.predict(X_new)[0]\n",
    "    elif model_type == 'lgbm':\n",
    "        model_loaded = lgb.Booster(model_file='lgbm_model.txt')\n",
    "        pred = model_loaded.predict(X_new)[0]\n",
    "    else:\n",
    "        raise ValueError(\"model_type musi być 'ridge' lub 'lgbm'\")\n",
    "    \n",
    "    return float(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_paths = [\n",
    "    'log_path_1'\n",
    "]\n",
    "\n",
    "metrics_paths = [\n",
    "    'log_path_2'\n",
    "]\n",
    "\n",
    "\n",
    "def get_actual_makespan_from_log(log_path):\n",
    "    import json\n",
    "    import pandas as pd\n",
    "\n",
    "    with open(log_path) as f:\n",
    "        logs = json.load(f)\n",
    "    logs_df = pd.DataFrame(logs)\n",
    "\n",
    "    workflow_end_log = logs_df[logs_df['body'].str.contains('Workflow finished', na=False)]\n",
    "\n",
    "    if workflow_end_log.empty:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        duration_seconds = float(workflow_end_log['log.attributes.timeInSeconds'].values[0])\n",
    "        return duration_seconds\n",
    "    except (KeyError, ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for log_path, metrics_path in zip(log_paths, metrics_paths):\n",
    "    try:\n",
    "        pred = predict_makespan_from_paths(log_path, metrics_path, model_type='lgbm')\n",
    "        actual = get_actual_makespan_from_log(log_path)\n",
    "        results.append({\n",
    "            # 'Log file': log_path.split('/')[-1],\n",
    "            'Predicted makespan (s)': round(pred, 2),\n",
    "            'Actual makespan (s)': round(actual, 2) if actual is not None else 'N/A',\n",
    "            'Error (s)': round(pred - actual, 2) if actual is not None else 'N/A'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            'Log file': log_path.split('/')[-1],\n",
    "            'Predicted makespan (s)': 'ERROR',\n",
    "            'Actual makespan (s)': 'ERROR',\n",
    "            'Error (s)': str(e)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperflow-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
